{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle  \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import *\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_classes(categ):\n",
    "    return np.array(list(map(lambda x:np.argmax(x),categ)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000117791</th>\n",
       "      <th>ENSG00000173838</th>\n",
       "      <th>ENSG00000184702</th>\n",
       "      <th>ENSG00000140623</th>\n",
       "      <th>ENSG00000121410</th>\n",
       "      <th>ENSG00000148584</th>\n",
       "      <th>ENSG00000175899</th>\n",
       "      <th>ENSG00000166535</th>\n",
       "      <th>ENSG00000118017</th>\n",
       "      <th>ENSG00000205002</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000166634</th>\n",
       "      <th>ENSG00000203870</th>\n",
       "      <th>ENSG00000188176</th>\n",
       "      <th>ENSG00000157703</th>\n",
       "      <th>ENSG00000107807</th>\n",
       "      <th>ENSG00000087128</th>\n",
       "      <th>ENSG00000164761</th>\n",
       "      <th>ENSG00000134588</th>\n",
       "      <th>ENSG00000243660</th>\n",
       "      <th>merged.numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-OR-A5K8-01</th>\n",
       "      <td>2.230</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>0.972</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>1.556</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>5.628</td>\n",
       "      <td>-4.608</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-4.293</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-3.626</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-3.171</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>1.334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1577-01</th>\n",
       "      <td>3.621</td>\n",
       "      <td>-2.932</td>\n",
       "      <td>4.006</td>\n",
       "      <td>-4.608</td>\n",
       "      <td>5.143</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>4.848</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>-5.574</td>\n",
       "      <td>0.276</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.012</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>4.540</td>\n",
       "      <td>0.688</td>\n",
       "      <td>-1.470</td>\n",
       "      <td>-3.816</td>\n",
       "      <td>0.979</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>2.428</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-146FR-0926-SM-5QGPE</th>\n",
       "      <td>4.173</td>\n",
       "      <td>-1.355</td>\n",
       "      <td>6.735</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>4.195</td>\n",
       "      <td>-3.047</td>\n",
       "      <td>6.540</td>\n",
       "      <td>-3.171</td>\n",
       "      <td>-5.574</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-1.056</td>\n",
       "      <td>1.064</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-2.826</td>\n",
       "      <td>-5.012</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>0.661</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-WE-AAA3-06</th>\n",
       "      <td>1.050</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>3.872</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>6.540</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>7.416</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>1.158</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-2.826</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-6.506</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-0.472</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-1.470</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-EM-A3FL-01</th>\n",
       "      <td>5.519</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>2.958</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>4.073</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>5.567</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-6.506</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-5.574</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>-6.506</td>\n",
       "      <td>6.651</td>\n",
       "      <td>-9.966</td>\n",
       "      <td>2.345</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3779 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ENSG00000117791  ENSG00000173838  ENSG00000184702  \\\n",
       "TCGA-OR-A5K8-01                     2.230           -9.966            0.972   \n",
       "TCGA-36-1577-01                     3.621           -2.932            4.006   \n",
       "GTEX-146FR-0926-SM-5QGPE            4.173           -1.355            6.735   \n",
       "TCGA-WE-AAA3-06                     1.050           -9.966            3.872   \n",
       "TCGA-EM-A3FL-01                     5.519           -9.966            2.958   \n",
       "\n",
       "                          ENSG00000140623  ENSG00000121410  ENSG00000148584  \\\n",
       "TCGA-OR-A5K8-01                    -9.966            1.556           -9.966   \n",
       "TCGA-36-1577-01                    -4.608            5.143           -9.966   \n",
       "GTEX-146FR-0926-SM-5QGPE           -9.966            4.195           -3.047   \n",
       "TCGA-WE-AAA3-06                    -9.966            6.540           -9.966   \n",
       "TCGA-EM-A3FL-01                    -9.966            4.073           -9.966   \n",
       "\n",
       "                          ENSG00000175899  ENSG00000166535  ENSG00000118017  \\\n",
       "TCGA-OR-A5K8-01                     5.628           -4.608           -9.966   \n",
       "TCGA-36-1577-01                     4.848           -0.320           -5.574   \n",
       "GTEX-146FR-0926-SM-5QGPE            6.540           -3.171           -5.574   \n",
       "TCGA-WE-AAA3-06                     7.416           -9.966           -9.966   \n",
       "TCGA-EM-A3FL-01                     5.567           -9.966           -9.966   \n",
       "\n",
       "                          ENSG00000205002       ...        ENSG00000166634  \\\n",
       "TCGA-OR-A5K8-01                    -4.293       ...                 -9.966   \n",
       "TCGA-36-1577-01                     0.276       ...                 -5.012   \n",
       "GTEX-146FR-0926-SM-5QGPE           -9.966       ...                 -9.966   \n",
       "TCGA-WE-AAA3-06                     1.158       ...                 -9.966   \n",
       "TCGA-EM-A3FL-01                    -6.506       ...                 -9.966   \n",
       "\n",
       "                          ENSG00000203870  ENSG00000188176  ENSG00000157703  \\\n",
       "TCGA-OR-A5K8-01                    -9.966           -3.626           -0.357   \n",
       "TCGA-36-1577-01                    -9.966            4.540            0.688   \n",
       "GTEX-146FR-0926-SM-5QGPE           -1.056            1.064           -9.966   \n",
       "TCGA-WE-AAA3-06                    -9.966           -2.826           -9.966   \n",
       "TCGA-EM-A3FL-01                    -9.966           -5.574            0.252   \n",
       "\n",
       "                          ENSG00000107807  ENSG00000087128  ENSG00000164761  \\\n",
       "TCGA-OR-A5K8-01                    -9.966           -9.966           -3.171   \n",
       "TCGA-36-1577-01                    -1.470           -3.816            0.979   \n",
       "GTEX-146FR-0926-SM-5QGPE           -2.826           -5.012           -0.072   \n",
       "TCGA-WE-AAA3-06                    -6.506           -9.966           -0.472   \n",
       "TCGA-EM-A3FL-01                    -9.966           -6.506            6.651   \n",
       "\n",
       "                          ENSG00000134588  ENSG00000243660  merged.numeric  \n",
       "TCGA-OR-A5K8-01                    -9.966            1.334               1  \n",
       "TCGA-36-1577-01                    -9.966            2.428              38  \n",
       "GTEX-146FR-0926-SM-5QGPE           -9.966            0.661              22  \n",
       "TCGA-WE-AAA3-06                    -9.966           -1.470              49  \n",
       "TCGA-EM-A3FL-01                    -9.966            2.345              57  \n",
       "\n",
       "[5 rows x 3779 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./1115-TRAIN-CANCER-NORMAL.csv\",sep=';',index_col=0,decimal=\",\").round(3)\n",
    "df = shuffle(df) \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x = 1/(1+np.exp(df.iloc[:,:-1])).values\n",
    "x=df.iloc[:,:-1].values\n",
    "y = df['merged.numeric'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training matrix shape (17404, 3778)\n",
      "Testing matrix shape (916, 3778)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.05)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "y_train = np_utils.to_categorical(y_train, 65)\n",
    "y_test = np_utils.to_categorical(y_test, 65)\n",
    "print(\"Training matrix shape\", x_train.shape)\n",
    "print(\"Testing matrix shape\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2000, activation='sigmoid', input_shape=(3778,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(800, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(65, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17404/17404 [==============================] - 1s 65us/step - loss: 2.8034 - acc: 0.3970\n",
      "Epoch 2/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.7793 - acc: 0.8200\n",
      "Epoch 3/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.3591 - acc: 0.9119\n",
      "Epoch 4/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.2480 - acc: 0.9384\n",
      "Epoch 5/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.2103 - acc: 0.9456\n",
      "Epoch 6/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1990 - acc: 0.9472\n",
      "Epoch 7/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1755 - acc: 0.9527\n",
      "Epoch 8/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1599 - acc: 0.9575\n",
      "Epoch 9/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1526 - acc: 0.9591\n",
      "Epoch 10/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1508 - acc: 0.9587\n",
      "Epoch 11/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1444 - acc: 0.9605\n",
      "Epoch 12/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1460 - acc: 0.9602\n",
      "Epoch 13/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1460 - acc: 0.9584\n",
      "Epoch 14/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1421 - acc: 0.9602\n",
      "Epoch 15/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1375 - acc: 0.9626\n",
      "Epoch 16/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1374 - acc: 0.9595\n",
      "Epoch 17/100\n",
      "17404/17404 [==============================] - 1s 34us/step - loss: 0.1283 - acc: 0.9632\n",
      "Epoch 18/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1406 - acc: 0.9599\n",
      "Epoch 19/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1478 - acc: 0.9582\n",
      "Epoch 20/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1430 - acc: 0.9587\n",
      "Epoch 21/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1304 - acc: 0.9607\n",
      "Epoch 22/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1469 - acc: 0.9552\n",
      "Epoch 23/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1511 - acc: 0.9565\n",
      "Epoch 24/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1374 - acc: 0.9596\n",
      "Epoch 25/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1360 - acc: 0.9593\n",
      "Epoch 26/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1340 - acc: 0.9608\n",
      "Epoch 27/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1256 - acc: 0.9633\n",
      "Epoch 28/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1249 - acc: 0.9630\n",
      "Epoch 29/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1257 - acc: 0.9631\n",
      "Epoch 30/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1300 - acc: 0.9601\n",
      "Epoch 31/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1319 - acc: 0.9606\n",
      "Epoch 32/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1217 - acc: 0.9623\n",
      "Epoch 33/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1315 - acc: 0.9597\n",
      "Epoch 34/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1427 - acc: 0.9563\n",
      "Epoch 35/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1310 - acc: 0.9600\n",
      "Epoch 36/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1271 - acc: 0.9598\n",
      "Epoch 37/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1405 - acc: 0.9580\n",
      "Epoch 38/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1395 - acc: 0.9558\n",
      "Epoch 39/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1453 - acc: 0.9559\n",
      "Epoch 40/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1281 - acc: 0.9593\n",
      "Epoch 41/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1311 - acc: 0.9591\n",
      "Epoch 42/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1427 - acc: 0.9557\n",
      "Epoch 43/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1379 - acc: 0.9565\n",
      "Epoch 44/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1518 - acc: 0.9532\n",
      "Epoch 45/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1322 - acc: 0.9576\n",
      "Epoch 46/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1254 - acc: 0.9609\n",
      "Epoch 47/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1300 - acc: 0.9606\n",
      "Epoch 48/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1339 - acc: 0.9581\n",
      "Epoch 49/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1207 - acc: 0.9616\n",
      "Epoch 50/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1244 - acc: 0.9611\n",
      "Epoch 51/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1056 - acc: 0.9667\n",
      "Epoch 52/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1263 - acc: 0.9601\n",
      "Epoch 53/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1137 - acc: 0.9643\n",
      "Epoch 54/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1073 - acc: 0.9671\n",
      "Epoch 55/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1165 - acc: 0.9621\n",
      "Epoch 56/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1250 - acc: 0.9602\n",
      "Epoch 57/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1244 - acc: 0.9597\n",
      "Epoch 58/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1245 - acc: 0.9585\n",
      "Epoch 59/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1103 - acc: 0.9656\n",
      "Epoch 60/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.0980 - acc: 0.9686\n",
      "Epoch 61/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1132 - acc: 0.9640\n",
      "Epoch 62/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1044 - acc: 0.9665\n",
      "Epoch 63/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1084 - acc: 0.9655\n",
      "Epoch 64/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1200 - acc: 0.9605\n",
      "Epoch 65/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1130 - acc: 0.9636\n",
      "Epoch 66/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1221 - acc: 0.9594\n",
      "Epoch 67/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1165 - acc: 0.9638\n",
      "Epoch 68/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1124 - acc: 0.9636\n",
      "Epoch 69/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1204 - acc: 0.9618\n",
      "Epoch 70/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1249 - acc: 0.9595\n",
      "Epoch 71/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1072 - acc: 0.9666\n",
      "Epoch 72/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1043 - acc: 0.9654\n",
      "Epoch 73/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1235 - acc: 0.9615\n",
      "Epoch 74/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1239 - acc: 0.9609\n",
      "Epoch 75/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1300 - acc: 0.9587\n",
      "Epoch 76/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1140 - acc: 0.9649\n",
      "Epoch 77/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1091 - acc: 0.9647\n",
      "Epoch 78/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1157 - acc: 0.9648\n",
      "Epoch 79/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1003 - acc: 0.9676\n",
      "Epoch 80/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1059 - acc: 0.9654\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.0999 - acc: 0.9682\n",
      "Epoch 82/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1099 - acc: 0.9650\n",
      "Epoch 83/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1186 - acc: 0.9614\n",
      "Epoch 84/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1031 - acc: 0.9671\n",
      "Epoch 85/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.0989 - acc: 0.9697\n",
      "Epoch 86/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.0980 - acc: 0.9690\n",
      "Epoch 87/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1163 - acc: 0.9623\n",
      "Epoch 88/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1059 - acc: 0.9667\n",
      "Epoch 89/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.0935 - acc: 0.9705\n",
      "Epoch 90/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.0932 - acc: 0.9698\n",
      "Epoch 91/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1042 - acc: 0.9662\n",
      "Epoch 92/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.1005 - acc: 0.9669\n",
      "Epoch 93/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.0833 - acc: 0.9726\n",
      "Epoch 94/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.0872 - acc: 0.9726\n",
      "Epoch 95/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.0951 - acc: 0.9687\n",
      "Epoch 96/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.1037 - acc: 0.9668\n",
      "Epoch 97/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.0950 - acc: 0.9691\n",
      "Epoch 98/100\n",
      "17404/17404 [==============================] - 1s 32us/step - loss: 0.0905 - acc: 0.9716\n",
      "Epoch 99/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.0970 - acc: 0.9689\n",
      "Epoch 100/100\n",
      "17404/17404 [==============================] - 1s 33us/step - loss: 0.0880 - acc: 0.9722\n",
      "916/916 [==============================] - 0s 53us/step\n",
      "Test loss: 0.204789189028\n",
      "Test accuracy: 0.951965064982\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=100,\n",
    "          batch_size=500)\n",
    "score = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916/916 [==============================] - 0s 49us/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pre=model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26 53 13 44 29 49 44  1 53 37 44 26 50 17 33 30 57 38 29 34 37 10 21 56 64\n",
      " 60 11 29 16 32 50 23 10  9 49 41 32 44 49  8 41 22 19 38 53  7 44 19  5 49\n",
      " 37 37 21 24 13 29 57 25 10 53 48 13 49 34 37 10 26 15 50  6 10 10 10 32 38\n",
      " 44 10 42 59 32  9 49 23 23 42 49 35 44 35 54 49 42 10 50 50 40 60 29 30 19\n",
      " 58 41 26 34 22 15 48 33 11 53 57  2 19 19 10  2  9 54 57 30 57 21 58 53  5\n",
      "  9 57 11 16 13 42 49 15 38 36 48 23 36 22 36 60 34 23  2 32 38 19 59 35 27\n",
      " 36 15 32 23 10  5 26 25 39 26 13  2 10 26  9 10 37 59 32 50 32 36 37 38 32\n",
      "  9 57 63 38 41 38  7 21 21  7  9 19 43 44 38 50  6 19 18  5 23 10 53 50 23\n",
      " 29 23 29 37 15 61  2 37 23 59 10 22 47 17 23 22 23  2 57 57 21 58 49  6 28\n",
      " 34 32 37 32 43 26  7 42 37 36 49 38  9  9 57 38  9 63 26  7 57 55 10 10 30\n",
      " 64 42  9  7  6 24 19  6 53 60 23 10 57 50 26 35 10  9  9 11 34 57 38 44 10\n",
      " 14 26  9 19 49 18 23 10 17 40 13 29 56 38 26 51 50 16 54  6  7 15 19 37 59\n",
      " 24 32 36 19  3 30 22 10 48 33 19 10  2  9  5 21 23  6 26 16 32 10  9 48  5\n",
      " 15  2  3 63 21 23 36 62  9 53  5 29 50 34 50 33  9 53 22 55 36 59 40  5 13\n",
      " 55 42 10 57 60 11 55 15 50 30 53  7 48 44 57 29  3 44 50 53  3  9 10 38 22\n",
      " 30 59 33 10 10 42 32  6 51 15 50 32 48  9 45 23 53 29 47 36 26 51 41 15 38\n",
      " 10 27 29 31 44 28 26 49 53 32  6  2 55 57 22 13 50 50 32 10 49  9  6 39 19\n",
      "  3 34 43 30 11 34 44 54 45 10 49 49 32  9 10 59  9 53  6 50 59  9 10 22 32\n",
      "  9  9  6 49 10 29 16 44 16 22 42 29  9  3 26 55  7 51 29 37 33  6 43 38 44\n",
      " 53 26 10 13 26 32 21 23 10 10 13  2 33 47 36 64 33 23 38 43 55 44  9 15 50\n",
      " 63 16 29 16  9 26 44 59 11 53 37  3 32 44 19 59  9 10 53 53 33 30 45 52 27\n",
      " 53 14  1 10 23  5 37 10 44 33 10  2 27  3 34  9 50  6 50 15 22 22 15 57 50\n",
      " 37 50 38 10 23  9 52 32 50 34 56 36  2 57 19  6 11 59 10 29 48 29 59  9  2\n",
      " 49 23 57 10 44 53  5 49 57 35 53 53 34  6 57 26 21  7  9 53 44 38 50 57 30\n",
      "  7 50 49 54 38 49 38 50  2 18 19 54 26 45 53 36 37 21  9 53 52 32 52 32 32\n",
      " 50 58 34  6 50 30 16 56 28 26 18 15 54 44 32 10 16 37 54 19 19 44  9 51 33\n",
      " 38 37  6 33  6  7 42 32  9 15 16  9 16 35  9 54 33 44  5 26 50 33  7  5  5\n",
      " 53  5 40 31 13 35 27  5  8 10 48 38 26 41 32  7 51 56 19  2 18 36 38 60 50\n",
      " 21 44 32  7 33 27 19 11 10 50 36 45 41 37 62 23 22 57 29 30 50  7 10 22 10\n",
      " 57 57 32 30 26 53 57  7 36  9 22 53 16 34 42 15 22 23 36 53 10 50 16 21 60\n",
      " 28  1 15 30 11 27 23 59 50 50 32 22 34 32  5  9  9 33  9  9  5 50  7  2 18\n",
      " 34  1 29 50  5 42 56 13 53 53 52 43 10 48 39 24 22 10 30 22 10 48 26 49 18\n",
      "  2 34 26 42 36 26 15 15 30 49 38  5 26 50 58  9  5 59  7 10 26 58 23 41 37\n",
      " 38 10 60 29 22 32 50 33 19 21 10 13 36 10 33 19 34 37 43 30 16 45 60 23 49\n",
      "  9 18 44  5 10 19  5 61  2 50 10 57 34 33  5  9 50 57 45 32 40 23 40 59 34\n",
      " 11 50 40 15 60 15 16 22  2 41 36 49 57 50  5 36  6 38 10  7 16 26 32 26  9\n",
      " 46 19  9  9 29  2  2  9  9 18 23 29 10 21 30 63]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48, 32, 10,  6, 57,  3, 32, 33, 49, 49, 57,  6, 32, 49, 19, 18, 10,\n",
       "       42, 55, 38,  2,  5, 55, 56,  2, 36, 10, 50, 32, 27, 61, 42, 25, 30,\n",
       "        7, 24, 29,  1, 29,  2, 53, 22, 55, 48, 34, 30, 34,  7, 50, 54, 38,\n",
       "       49, 15, 50,  3, 61,  3, 40, 18, 40, 30, 18, 41, 49,  9, 50, 19, 60,\n",
       "       29, 11, 57, 41, 16, 13, 13, 34, 48,  2, 45,  9, 39, 22, 19, 21, 11,\n",
       "       28,  7, 34, 10, 10, 44, 10, 28, 48, 13, 48, 23, 38, 27, 23, 39, 22,\n",
       "       38, 44,  6, 23, 18, 32, 57, 59,  7, 39, 16, 19, 38, 32, 49, 28, 62,\n",
       "       11, 38, 13, 38, 23, 13, 60, 50, 10, 52,  5, 42, 19, 53, 49, 10, 19,\n",
       "       53, 32, 10, 22, 38, 26, 54, 34, 33, 57,  2, 49,  7, 19, 48, 44, 62,\n",
       "       37, 22, 60,  7, 10,  6,  2, 33, 50,  2, 45, 40, 57, 44, 41, 10, 53,\n",
       "       40, 19,  9, 38,  9, 13, 21, 32, 22, 49, 10, 44, 50, 29, 15,  2, 30,\n",
       "        9, 21, 36, 23, 15,  9, 44, 10, 26, 26, 26,  5, 61, 54, 32,  5, 53,\n",
       "       15, 48, 34, 43, 19, 29, 29,  9, 37, 30, 29, 63, 26, 64, 58, 26, 34,\n",
       "       53, 36, 26, 29, 32, 59, 54, 33, 50, 45, 13, 23,  9, 19, 32, 19, 15,\n",
       "       47,  9, 48, 18, 44, 44, 10, 38,  9, 50, 18, 58,  2,  7, 16, 29, 49,\n",
       "       49, 50, 44,  2, 57, 32,  5,  2, 44,  5, 13, 31, 27, 27, 49, 34, 54,\n",
       "       29, 57, 64, 49, 23, 26,  9, 39,  9, 56, 10, 32,  7, 34, 44, 10,  5,\n",
       "       19, 52, 34, 53, 42, 42, 10, 48, 15, 49,  8, 30,  2,  9,  5, 57,  2,\n",
       "       26, 38,  9, 44, 10, 32, 10, 10, 51,  7, 32,  9, 60,  5, 22, 30, 10,\n",
       "       10, 53, 56, 55,  6, 21, 53, 49,  7, 39,  5,  7, 36,  2, 32, 10, 29,\n",
       "        5, 50, 57, 35, 44, 48,  1, 32, 57, 29, 30, 34, 49, 10, 28, 49,  9,\n",
       "       35,  7, 36, 64,  5, 19, 49, 32, 58, 10, 26, 30, 26, 50, 48, 26, 34,\n",
       "       58, 17, 34,  6, 22,  2, 58,  2, 12, 36, 34, 16, 57, 10, 32, 22, 18,\n",
       "       49,  5, 32, 29, 10, 23,  2, 23, 50, 30,  7, 28, 59, 26, 34, 10, 19,\n",
       "       37,  8, 64, 54, 48, 38,  9, 41, 10,  9, 49, 27, 38,  9, 57, 19,  7,\n",
       "        2, 42, 10, 44, 26, 10, 57, 29, 49,  6, 40, 22, 13, 10,  2,  6,  8,\n",
       "       36, 38, 63, 32, 64,  4, 19, 54,  9, 32, 29,  9, 49, 19,  2, 50, 59,\n",
       "       31,  3, 50, 16, 10,  2, 34, 10, 59, 59, 44,  9, 50, 50, 64, 44, 15,\n",
       "       28, 53, 41, 42, 29, 34,  8, 19, 10, 34, 22, 34, 10,  9, 15, 19, 46,\n",
       "       15, 53, 50, 57, 23, 52, 54, 50, 26,  9,  2, 35,  2, 29, 23, 19, 40,\n",
       "       29, 44, 13, 37, 32, 13, 21, 48,  9, 18,  9, 57, 39, 59, 23,  1, 23,\n",
       "       14, 42,  9, 36,  5,  9,  9, 15, 32, 50, 10, 29, 33, 10, 26, 23,  9,\n",
       "       55,  2, 32, 25, 27,  9, 50, 29, 53, 50,  1, 50, 15, 26, 40, 54, 50,\n",
       "       34, 36, 16, 49, 28, 10, 42, 26, 36, 21, 59, 50, 63, 50, 29, 30, 44,\n",
       "        9, 57, 52, 22, 10, 50,  7, 15,  9, 34, 23, 29, 57, 40, 15, 50, 19,\n",
       "       32, 53, 51, 15,  9,  9, 23, 19,  7, 18, 50, 23, 53, 32, 10, 35, 10,\n",
       "       16, 53, 10, 38, 39, 22, 59, 57,  1, 11,  9, 16,  2, 57, 15, 37, 37,\n",
       "        7, 49, 50,  7, 53, 55, 23,  6,  9, 16,  8, 57,  2, 26, 38, 38,  6,\n",
       "       40,  7, 14, 57, 30, 38, 37, 50, 50, 23, 18, 32, 30, 16, 35,  2, 34,\n",
       "       57, 44, 19, 32, 45, 33,  6, 33, 16, 53, 57, 19, 49,  9, 29, 54, 50,\n",
       "       43, 32, 58, 53, 43,  6, 22, 53, 34, 30, 19, 29, 10,  9, 16,  2, 56,\n",
       "       27, 51, 40,  9, 33, 57, 63, 50, 30, 32, 22, 38, 44, 50, 44, 54, 50,\n",
       "       59, 22, 56, 49, 10, 19, 60, 19, 16, 10, 57, 22, 51, 50, 29, 22,  2,\n",
       "       61, 32, 16,  9,  9, 27, 64, 59, 32, 27,  2, 34, 57, 45, 23, 21, 19,\n",
       "       50, 29, 32, 46,  5,  2, 32, 60, 56,  9, 15, 29, 44, 21,  3, 30,  9,\n",
       "       36, 19, 42, 49, 10, 26, 22, 44, 10, 44, 26, 36, 44, 46, 16, 18, 28,\n",
       "       13, 30, 50, 26, 50, 49,  2, 29, 34,  2, 27, 29, 59, 60, 13, 57,  6,\n",
       "       60, 16, 42, 32, 53, 41,  2, 23, 49, 53, 48,  9,  6, 22,  3,  9,  9,\n",
       "       34, 15, 44, 10,  9,  5, 16, 13, 10,  9, 27, 10, 29, 22,  9, 33, 23,\n",
       "       30,  7, 21, 44, 22, 27, 27, 42, 19, 37, 38, 54, 33, 50, 54, 53,  9,\n",
       "        2, 56,  2, 48, 32, 10, 64, 57, 50, 11, 17,  9, 27,  7, 10, 62, 26,\n",
       "        5, 55, 38, 42,  8, 32, 50, 57, 44, 60, 10, 30, 29, 16, 23,  7, 48,\n",
       "       40, 29, 55, 44, 50, 34,  5, 19, 53, 44, 23, 56, 36, 51, 22, 29, 44,\n",
       "       10, 36, 54,  6, 57, 14, 48, 52, 21, 19, 37, 41, 11, 32, 46])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "icgc=pd.read_csv(\"./ICGC-EXPR.csv\",sep=';',index_col=0,decimal=\",\").round(3).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "icgc=np.log2(icgc+0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test=icgc.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "icgc_out=open('../03.icgc/icgc_class_pre.txt','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",18,15,28,23,10,57,26,24,17,21,28,38,10,57,60,38,10,40,48,38,10,10,26,30,30,30,17,38,28,17,53,27,38,26,30,38,26,26,26,57,17,30,10,10,10,17,26,38,44,49,17,10,26,10,34,44,10,24,30,60,10,30,38,32,32,10,49,38,40,26,26,34,15,28,13,10,38,49,40,30,60,21,24,29,30,34,6,24,26,28,57,26,49,34,49,10,40,29,38,27,24,38,6,17,32,26,10,17,44,29,53,38,6,26,17,24,38,23,53,17,27,34,24,24,30,24,38,17,27,38,34,26,57,30,24,26,57,26,13,5,23,26,38,23,49,17,17,60,32,30,57,10,29,38,17,53,13,49,30,13,10,38,17,53,6,60,38,32,6,40,26,17,5,17,27,15,49,30,17,10,17,26,38,53,49,6,30,10,23,21,57,17,13,32,23,29,38,40,23,10,23,32,26,34,21,15,26,49,10,46,23,57,57,57,34,40,57,28,24,26,10,34,34,60,38,26,49,10,26,32,34,38,26,29,60,5,32,26,23,30,21,40,34,40,10,6,46,48,38,53,6,26,38,6,28,6,23,5,21,49,38,32,30,34,34,38,49,32,6,27,17,30,32,26,60,60,23,26,10,48,57,26,17,21,10,28,13,34,26,26,26,60,32,53,32,5,5,34,26,26,30,53,23,10,6,10,10,57,6,15,32,10,23,5,38,29,28,6,44,28,6,17,38,13,10,34,26,17,49,53,26,53,38,29,6,44,28,38,30,30,40,53,46,10,10,24,38,6,10,34,30,60,48,24,15,26,27,57,24,38,15,53,60,38,6,17,29,30,57,32,32,48,23,26,10,29,15,10,60,48,23,10,26,21,29,60,26,53,26,15,17,57,15,57,53,26,26,48,17,34,30,26,26,34,27,26,30,17,38,60,23,28,28,48,10,60,23,48,57,6,10,26,26,13,26,26,10,30,60,38,10,53,26,38,15,38,26,17,30,46,34,40,60,10,28,40,32,6,38,38,18,46,24,10,26,17,5,30,38,57,28,48,26,38,6,5,30,13,30,38,26,15,10,49,49,26,40,5,60,6,38,10,28,23,26,26,21,21,26,10,26,15,26,26,23,48,40,10,26,17,30,32,53,32,26,38,38,38,17,10,15,6,32,10,17,44,26,46,24,24,32,17,38,28,26,10,10,48,28,29,53,32,13,23,26,23,17,21,6,53,28,23,53,34,53,10,53,53,32,38,26,24,17,32,17,26,29,44,6,53,26,23,10,10,10,23,60,38,29,13,38,27,26,32,24,60,26,38,38,17,6,38,29,49,29,26,26,10,10,38,34,26,17,23,27,23,24,38,34,27,38,26,40,26,53,48,53,10,17,34,53,26,26,10,28,38,26,44,40,6,10,38,10,53,10,34,38,49,17,26,34,49,26,6,30,10,24,49,26,38,32,49,44,48,17,34,28,5,53,44,10,28,30,38,46,32,44,27,26,26,38,10,57,57,26,21,30,57,23,17,40,34,48,46,53,10,26,17,32,57,60,26,6,24,23,17,32,23,26,17,32,26,26,26,28,10,17,10,26,17,38,23,26,10,34,32,40,17,34,40,26,40,48,57,53,17,49,40,30,30,30,30,30,30,30,30,14,30,30,30,30,14,30,30,30,30,30,30,30,31,30,30,30,30,30,14,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,14,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,14,32,30,30,30,14,30,14,30,30,14,30,30,30,30,30,30,14,30,14,30,14,30,30,30,30,30,14,14,14,30,53,30,30,30,30,14,30,30,30,38,40,57,24,26,38,17,26,24,6,53,32,30,28,48,49,46,23,29,46,28,27,6,15,24,34,5,38,40,49,10,26,17,53,57,53,60,10,53,46,15,23,38,29,24,32,26,53,21,10,34,38,57,26,23,57,57,57,27,28,34,10,15,30,26,26,23,53,49,15,44,44,38,48,48,24,18,38,6,26,48,24,17,6,27,38,26,49,27,57,57,57,57,5,10,57,57,57,57,46,23,10,32,38,32,13,60,26,17,38,38,17,38,30,17,49,15,10,38,38,13,49,32,17,57,17,13,26,10,28,26,44,46,46,24,38,17,26,27,49,57,17,49,6,26,17,57,44,32,6,34,26,26,24,23,53,60,38,28,38,26,10,34,26,28,34,38,34,26,10,10,24,28,32,53,27,10,60,46,40,15,38,38,6,46,21,44,48,28,30,30,53,17,32,5,26,34,40,34,10,26,38,17,38,57,17,5,38,26,13,38,5,17,26,53,24,26,40,30,38,46,10,60,26,44,15,38,10,17,17,17,32,17,38,32,60,38,10,21,5,53,32,32,48,38,6,24,6,29,26,15,34,30,53,28,17,6,38,10,38,49,38,57,34,53,26,15,6,5,26,30,17,48,26,49,38,6,5,24,60,10,26,30,60,30,6,24,53,26,60,32,26,38,23,40,32,53,32,57,17,38,26,17,17,38,15,26,38,6,34,30,27,57,26,40,6,6,23,38,26,49,38,21,23,6,30,24,26,23,28,34,40,17,38,24,49,10,24,17,17,32,27,57,24,21,10,6,30,53,10,29,17,15,26,10,6,5,38,10,21,10,32,23,21,17,24,44,6,27,10,27,5,17,17,34,30,17,32,40,26,49,18,26,40,26,28,26,48,60,32,60,49,38,40,26,34,17,15,38,24,10,17,38,15,32,34,38,60,38,48,30,32,29,15,38,13,60,60,38,23,57,30,27,60,10,44,34,32,27,17,5,23,6,17,10,28,24,6,10,32,34,40,6,5,28,38,26,32,26,21,26,57,38,6,26,17,49,23,6,10,38,57,53,24,44,48,10,24,17,28,38,29,26,5,6,40,17,26,48,38,23,6,15,26,48,26,44,26,6,32,49,6,10,24,26,10,10,32,38,26,38,49,48,60,6,26,10,38,53,40,24,38,10,26,27,6,17,21,48,26,26,34,6,61,28,26,26,6,24,17,17,5,6,26,57,38,46\n"
     ]
    }
   ],
   "source": [
    "s=''\n",
    "for i in y_test_pre:\n",
    "    s=s+','+str(i)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pre[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=1/(1+np.exp(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2000)              7558000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 800)               1600800   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 65)                52065     \n",
      "=================================================================\n",
      "Total params: 9,210,865\n",
      "Trainable params: 9,210,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.00700000e+03,   1.44000000e+02,   4.90000000e+01,\n",
       "          3.90000000e+01,   5.10000000e+01,   4.30000000e+01,\n",
       "          2.90000000e+01,   2.90000000e+01,   2.90000000e+01,\n",
       "          2.80000000e+01,   2.60000000e+01,   2.60000000e+01,\n",
       "          2.00000000e+01,   2.20000000e+01,   1.70000000e+01,\n",
       "          1.30000000e+01,   2.10000000e+01,   1.80000000e+01,\n",
       "          0.00000000e+00,   1.50000000e+01,   2.10000000e+01,\n",
       "          9.00000000e+00,   1.70000000e+01,   9.00000000e+00,\n",
       "          0.00000000e+00,   1.30000000e+01,   1.90000000e+01,\n",
       "          1.40000000e+01,   1.40000000e+01,   0.00000000e+00,\n",
       "          1.00000000e+01,   7.00000000e+00,   1.40000000e+01,\n",
       "          7.00000000e+00,   1.20000000e+01,   0.00000000e+00,\n",
       "          2.20000000e+01,   1.50000000e+01,   1.30000000e+01,\n",
       "          1.30000000e+01,   0.00000000e+00,   1.20000000e+01,\n",
       "          4.00000000e+00,   1.40000000e+01,   4.00000000e+00,\n",
       "          9.00000000e+00,   1.10000000e+01,   0.00000000e+00,\n",
       "          9.00000000e+00,   8.00000000e+00,   4.00000000e+00,\n",
       "          6.00000000e+00,   1.00000000e+01,   1.00000000e+01,\n",
       "          0.00000000e+00,   8.00000000e+00,   9.00000000e+00,\n",
       "          8.00000000e+00,   6.00000000e+00,   5.00000000e+00,\n",
       "          5.00000000e+00,   8.00000000e+00,   9.00000000e+00,\n",
       "          6.00000000e+00,   9.00000000e+00,   6.00000000e+00,\n",
       "          8.00000000e+00,   3.00000000e+00,   8.00000000e+00,\n",
       "          5.00000000e+00,   0.00000000e+00,   1.60000000e+01,\n",
       "          5.00000000e+00,   4.00000000e+00,   8.00000000e+00,\n",
       "          1.20000000e+01,   2.00000000e+00,   7.00000000e+00,\n",
       "          8.00000000e+00,   7.00000000e+00,   4.00000000e+00,\n",
       "          5.00000000e+00,   3.00000000e+00,   5.00000000e+00,\n",
       "          5.00000000e+00,   1.20000000e+01,   4.00000000e+00,\n",
       "          4.00000000e+00,   1.00000000e+00,   5.00000000e+00,\n",
       "          1.40000000e+01,   3.00000000e+00,   5.00000000e+00,\n",
       "          1.00000000e+00,   9.00000000e+00,   3.00000000e+00,\n",
       "          6.00000000e+00,   7.00000000e+00,   5.00000000e+00,\n",
       "          3.00000000e+00,   6.00000000e+00,   5.00000000e+00,\n",
       "          1.00000000e+01,   2.00000000e+00,   1.00000000e+01,\n",
       "          3.00000000e+00,   6.00000000e+00,   6.00000000e+00,\n",
       "          1.20000000e+01,   6.00000000e+00,   1.00000000e+01,\n",
       "          7.00000000e+00,   7.00000000e+00,   9.00000000e+00,\n",
       "          4.00000000e+00,   3.00000000e+00,   8.00000000e+00,\n",
       "          5.00000000e+00,   8.00000000e+00,   2.00000000e+00,\n",
       "          3.00000000e+00,   9.00000000e+00,   3.00000000e+00,\n",
       "          6.00000000e+00,   3.00000000e+00,   5.00000000e+00,\n",
       "          3.00000000e+00,   8.00000000e+00,   4.00000000e+00,\n",
       "          5.00000000e+00,   4.00000000e+00,   7.00000000e+00,\n",
       "          5.00000000e+00,   1.20000000e+01,   9.00000000e+00,\n",
       "          6.00000000e+00,   8.00000000e+00,   5.00000000e+00,\n",
       "          4.00000000e+00,   4.00000000e+00,   2.00000000e+00,\n",
       "          7.00000000e+00,   9.00000000e+00,   1.20000000e+01,\n",
       "          7.00000000e+00,   7.00000000e+00,   8.00000000e+00,\n",
       "          1.00000000e+01,   9.00000000e+00,   9.00000000e+00,\n",
       "          8.00000000e+00,   7.00000000e+00,   8.00000000e+00,\n",
       "          4.00000000e+00,   5.00000000e+00,   9.00000000e+00,\n",
       "          3.00000000e+00,   8.00000000e+00,   8.00000000e+00,\n",
       "          7.00000000e+00,   4.00000000e+00,   6.00000000e+00,\n",
       "          1.00000000e+01,   3.00000000e+00,   5.00000000e+00,\n",
       "          1.40000000e+01,   1.10000000e+01,   8.00000000e+00,\n",
       "          8.00000000e+00,   9.00000000e+00,   1.30000000e+01,\n",
       "          1.10000000e+01,   1.20000000e+01,   1.20000000e+01,\n",
       "          1.00000000e+01,   3.00000000e+00,   9.00000000e+00,\n",
       "          1.40000000e+01,   1.40000000e+01,   1.60000000e+01,\n",
       "          1.70000000e+01,   1.90000000e+01,   1.60000000e+01,\n",
       "          1.60000000e+01,   1.90000000e+01,   2.00000000e+01,\n",
       "          2.30000000e+01,   2.40000000e+01,   2.70000000e+01,\n",
       "          2.50000000e+01,   2.80000000e+01,   3.10000000e+01,\n",
       "          3.20000000e+01,   3.60000000e+01,   3.70000000e+01,\n",
       "          5.70000000e+01,   7.80000000e+01,   6.30000000e+01,\n",
       "          1.43000000e+02,   2.54000000e+02]),\n",
       " array([  4.69678780e-05,   5.04672529e-03,   1.00464827e-02,\n",
       "          1.50462401e-02,   2.00459975e-02,   2.50457549e-02,\n",
       "          3.00455124e-02,   3.50452698e-02,   4.00450272e-02,\n",
       "          4.50447846e-02,   5.00445420e-02,   5.50442994e-02,\n",
       "          6.00440568e-02,   6.50438142e-02,   7.00435716e-02,\n",
       "          7.50433291e-02,   8.00430865e-02,   8.50428439e-02,\n",
       "          9.00426013e-02,   9.50423587e-02,   1.00042116e-01,\n",
       "          1.05041874e-01,   1.10041631e-01,   1.15041388e-01,\n",
       "          1.20041146e-01,   1.25040903e-01,   1.30040661e-01,\n",
       "          1.35040418e-01,   1.40040175e-01,   1.45039933e-01,\n",
       "          1.50039690e-01,   1.55039448e-01,   1.60039205e-01,\n",
       "          1.65038962e-01,   1.70038720e-01,   1.75038477e-01,\n",
       "          1.80038235e-01,   1.85037992e-01,   1.90037750e-01,\n",
       "          1.95037507e-01,   2.00037264e-01,   2.05037022e-01,\n",
       "          2.10036779e-01,   2.15036537e-01,   2.20036294e-01,\n",
       "          2.25036051e-01,   2.30035809e-01,   2.35035566e-01,\n",
       "          2.40035324e-01,   2.45035081e-01,   2.50034838e-01,\n",
       "          2.55034596e-01,   2.60034353e-01,   2.65034111e-01,\n",
       "          2.70033868e-01,   2.75033626e-01,   2.80033383e-01,\n",
       "          2.85033140e-01,   2.90032898e-01,   2.95032655e-01,\n",
       "          3.00032413e-01,   3.05032170e-01,   3.10031927e-01,\n",
       "          3.15031685e-01,   3.20031442e-01,   3.25031200e-01,\n",
       "          3.30030957e-01,   3.35030714e-01,   3.40030472e-01,\n",
       "          3.45030229e-01,   3.50029987e-01,   3.55029744e-01,\n",
       "          3.60029502e-01,   3.65029259e-01,   3.70029016e-01,\n",
       "          3.75028774e-01,   3.80028531e-01,   3.85028289e-01,\n",
       "          3.90028046e-01,   3.95027803e-01,   4.00027561e-01,\n",
       "          4.05027318e-01,   4.10027076e-01,   4.15026833e-01,\n",
       "          4.20026590e-01,   4.25026348e-01,   4.30026105e-01,\n",
       "          4.35025863e-01,   4.40025620e-01,   4.45025378e-01,\n",
       "          4.50025135e-01,   4.55024892e-01,   4.60024650e-01,\n",
       "          4.65024407e-01,   4.70024165e-01,   4.75023922e-01,\n",
       "          4.80023679e-01,   4.85023437e-01,   4.90023194e-01,\n",
       "          4.95022952e-01,   5.00022709e-01,   5.05022466e-01,\n",
       "          5.10022224e-01,   5.15021981e-01,   5.20021739e-01,\n",
       "          5.25021496e-01,   5.30021254e-01,   5.35021011e-01,\n",
       "          5.40020768e-01,   5.45020526e-01,   5.50020283e-01,\n",
       "          5.55020041e-01,   5.60019798e-01,   5.65019555e-01,\n",
       "          5.70019313e-01,   5.75019070e-01,   5.80018828e-01,\n",
       "          5.85018585e-01,   5.90018342e-01,   5.95018100e-01,\n",
       "          6.00017857e-01,   6.05017615e-01,   6.10017372e-01,\n",
       "          6.15017130e-01,   6.20016887e-01,   6.25016644e-01,\n",
       "          6.30016402e-01,   6.35016159e-01,   6.40015917e-01,\n",
       "          6.45015674e-01,   6.50015431e-01,   6.55015189e-01,\n",
       "          6.60014946e-01,   6.65014704e-01,   6.70014461e-01,\n",
       "          6.75014218e-01,   6.80013976e-01,   6.85013733e-01,\n",
       "          6.90013491e-01,   6.95013248e-01,   7.00013006e-01,\n",
       "          7.05012763e-01,   7.10012520e-01,   7.15012278e-01,\n",
       "          7.20012035e-01,   7.25011793e-01,   7.30011550e-01,\n",
       "          7.35011307e-01,   7.40011065e-01,   7.45010822e-01,\n",
       "          7.50010580e-01,   7.55010337e-01,   7.60010095e-01,\n",
       "          7.65009852e-01,   7.70009609e-01,   7.75009367e-01,\n",
       "          7.80009124e-01,   7.85008882e-01,   7.90008639e-01,\n",
       "          7.95008396e-01,   8.00008154e-01,   8.05007911e-01,\n",
       "          8.10007669e-01,   8.15007426e-01,   8.20007183e-01,\n",
       "          8.25006941e-01,   8.30006698e-01,   8.35006456e-01,\n",
       "          8.40006213e-01,   8.45005971e-01,   8.50005728e-01,\n",
       "          8.55005485e-01,   8.60005243e-01,   8.65005000e-01,\n",
       "          8.70004758e-01,   8.75004515e-01,   8.80004272e-01,\n",
       "          8.85004030e-01,   8.90003787e-01,   8.95003545e-01,\n",
       "          9.00003302e-01,   9.05003059e-01,   9.10002817e-01,\n",
       "          9.15002574e-01,   9.20002332e-01,   9.25002089e-01,\n",
       "          9.30001847e-01,   9.35001604e-01,   9.40001361e-01,\n",
       "          9.45001119e-01,   9.50000876e-01,   9.55000634e-01,\n",
       "          9.60000391e-01,   9.65000148e-01,   9.69999906e-01,\n",
       "          9.74999663e-01,   9.79999421e-01,   9.84999178e-01,\n",
       "          9.89998935e-01,   9.94998693e-01,   9.99998450e-01]),\n",
       " <a list of 200 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x184c52f8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(1/(1+np.exp(-x_train[1])),bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
